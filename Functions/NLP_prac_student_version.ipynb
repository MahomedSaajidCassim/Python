{"cells":[{"cell_type":"markdown","metadata":{"id":"-SBoXB0ivtFa"},"source":["# NLP Practical Test\n","\n","Â© Explore Data Science Academy\n","\n","The NLP practical test will take place within this Jupyter notebook. Each question will require you to write a function which will return the answer. This notebook will be graded automatically, so it is important that the names of any existing variables and functions are left unchanged.\n","\n","A shell function with the correct name for each question has already been defined for you. You will simply need to fill in the necessary code inside the function, as directed by the comments."]},{"cell_type":"markdown","metadata":{"id":"va2owsKIvtFh"},"source":["## Honour Code\n","\n","I **Mahomed Saajid**, **Cassim**, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the EDSA honour code (https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n","\n","Non-compliance with the honour code constitutes a material breach of contract."]},{"cell_type":"markdown","metadata":{"id":"itsVswg6vtFi"},"source":["#### Import Libraries and Read In the Data\n","\n","Do not modify or remove any of the code in these cells."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vT0vx9R9vtFj","executionInfo":{"status":"ok","timestamp":1675888676535,"user_tz":-120,"elapsed":2443,"user":{"displayName":"Mahomed Saajid Cassim","userId":"03411706528132358067"}},"outputId":"70de9f0f-2ed4-4405-86ad-b5b6850772f4"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}],"source":["import nltk\n","from nltk import TreebankWordTokenizer, SnowballStemmer\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","import string\n","import urllib\n","\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","nltk.download('omw-1.4')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GpKUoDuPvtFk","executionInfo":{"status":"ok","timestamp":1675888686959,"user_tz":-120,"elapsed":454,"user":{"displayName":"Mahomed Saajid Cassim","userId":"03411706528132358067"}},"outputId":"19177ee4-3eb7-4bf9-faf3-5a7f3de774a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Alice's Adventures in Wonderland\n","\n","                ALICE'S ADVENTURES IN WONDERLAND\n","\n","                          Lewis Carroll\n","\n","               THE MILLENNIUM FULCRUM EDITION 3.0\n","\n","\n","\n","\n","                            CHAPTER I\n","\n","                      Down the Rabbit-Hole\n","\n","\n","  Alice was beginning to get very tired of sitting by her sister\n","on the bank, and of having nothing to do:  once or twice she had\n","peeped into the book her sister was reading, but it had no\n","pictures or conversations in it, `and what is the use of a book,'\n","thought Alice `without pictures or conversation?'\n","\n","  So she was considering in her own mind (as well as she could,\n","for the hot day made her feel very sleepy and stupid), whether\n","the pleasure of making a daisy-chain would be worth the trouble\n","of getting up and picking the daisies, when suddenly a White\n","Rabbit with pink eyes ran close by her.\n","\n"," \n"]}],"source":["# read in the data\n","def print_some_url():\n","    with urllib.request.urlopen('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/classification_sprint//alice_in_wonderland.txt') as f:\n","        return f.read().decode('ISO-8859-1')\n","\n","data = print_some_url()\n","print(data[:863])"]},{"cell_type":"markdown","metadata":{"id":"-dVAGQUnvtFl"},"source":["#### Convert to lowercase and remove punctuation  \n","\n","Do not change or remove any of the code in these cells"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"S1RzDNEyvtFm","executionInfo":{"status":"ok","timestamp":1675888691755,"user_tz":-120,"elapsed":396,"user":{"displayName":"Mahomed Saajid Cassim","userId":"03411706528132358067"}}},"outputs":[],"source":["def remove_punctuation(words):\n","    words = words.lower()\n","    return ''.join([x for x in words if x not in string.punctuation])"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"4dIeC6_rvtFm","executionInfo":{"status":"ok","timestamp":1675888693922,"user_tz":-120,"elapsed":7,"user":{"displayName":"Mahomed Saajid Cassim","userId":"03411706528132358067"}}},"outputs":[],"source":["data = remove_punctuation(data)"]},{"cell_type":"markdown","metadata":{"id":"C97HXLj8vtFn"},"source":["#### Creating a bag of words and assigning our stemmer and lemmatizer\n","\n","Pay special attention to what these functions return and how the subsequent texts and lists look"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"V1I3Z6OyvtFn","executionInfo":{"status":"ok","timestamp":1675888698717,"user_tz":-120,"elapsed":2709,"user":{"displayName":"Mahomed Saajid Cassim","userId":"03411706528132358067"}}},"outputs":[],"source":["# define stemmer function\n","stemmer = SnowballStemmer('english')\n","\n","# tokenise data\n","tokeniser = TreebankWordTokenizer()\n","tokens = tokeniser.tokenize(data)\n","\n","# define lemmatiser\n","lemmatizer = WordNetLemmatizer()\n","\n","# bag of words\n","def bag_of_words_count(words, word_dict={}):\n","    \"\"\" this function takes in a list of words and returns a dictionary \n","        with each word as a key, and the value represents the number of \n","        times that word appeared\"\"\"\n","    for word in words:\n","        if word in word_dict.keys():\n","            word_dict[word] += 1\n","        else:\n","            word_dict[word] = 1\n","    return word_dict\n","\n","# remove stopwords\n","tokens_less_stopwords = [word for word in tokens if word not in stopwords.words('english')]\n","\n","# create bag of words\n","bag_of_words = bag_of_words_count(tokens_less_stopwords)"]},{"cell_type":"markdown","metadata":{"id":"Gulv_804vtFo"},"source":["## Question 1"]},{"cell_type":"markdown","metadata":{"id":"o5JKnYiXvtFo"},"source":["Use the stemmer and lemmatizer functions (defined in the cells above) from the relevant library to find the stem and lemma of the nth word in the token list.\n","\n","_**Function Specifications:**_\n","* Should take a `list` as input and return a  `dict` type as output.\n","* The dictionary should have the keys **'original',  'stem' and 'lemma'** with the corresponding values being the nth word transformed in that way."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Ru4OWFQNvtFo","executionInfo":{"status":"ok","timestamp":1675888721938,"user_tz":-120,"elapsed":386,"user":{"displayName":"Mahomed Saajid Cassim","userId":"03411706528132358067"}}},"outputs":[],"source":["### START FUNCTION\n","\n","def find_roots(token_list, n):\n","    # your code here\n","    result = dict()\n","    original = token_list[n-1]\n","    stem = stemmer.stem(original)\n","    lemma = lemmatizer.lemmatize(original)\n","    result = dict((('original', original),\n","             ('stem', stem),\n","             ('lemma', lemma)))\n","    return result\n","    \n","\n","### END FUNCTION"]},{"cell_type":"code","execution_count":7,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"hLU2fkMavtFp","executionInfo":{"status":"ok","timestamp":1675888726771,"user_tz":-120,"elapsed":1771,"user":{"displayName":"Mahomed Saajid Cassim","userId":"03411706528132358067"}},"outputId":"3b8b392a-8fce-42be-9aba-1727579a0eee"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'original': 'daisies', 'stem': 'daisi', 'lemma': 'daisy'}"]},"metadata":{},"execution_count":7}],"source":["find_roots(tokens, 120) "]},{"cell_type":"markdown","metadata":{"id":"6FuOhkyrvtFp"},"source":["_**Expected Outputs:**_\n","```python\n","find_roots(tokens, 120) == \n","{'original': 'daisies', \n","'stem': 'daisi', \n","'lemma': 'daisy'}\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"yEc0g5c8vtFp"},"source":["## Question 2"]},{"cell_type":"markdown","metadata":{"id":"yaGPomJSvtFq"},"source":["How many stopwords are in the text in total?   \n","\n","_Hint_ : you can use the nltk stopwords dictionary \n","\n","_**Function Specifications:**_\n","* Function should take a `list` as input \n","* The number of stopwords should be returned as an `int` "]},{"cell_type":"code","execution_count":8,"metadata":{"id":"tpcpQpHOvtFq","executionInfo":{"status":"ok","timestamp":1675888750228,"user_tz":-120,"elapsed":390,"user":{"displayName":"Mahomed Saajid Cassim","userId":"03411706528132358067"}}},"outputs":[],"source":["### START FUNCTION\n","def count_stopwords(token_list):\n","    # your code here\n","    count = 0\n","    stop_words = stopwords.words('english')\n","    for word in token_list:\n","        if word in stop_words:\n","            count+=1\n","    return count\n","    \n","\n","### END FUNCTION"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DK_W5eVIvtFq","executionInfo":{"status":"ok","timestamp":1675888754377,"user_tz":-120,"elapsed":381,"user":{"displayName":"Mahomed Saajid Cassim","userId":"03411706528132358067"}},"outputId":"2dc5c35d-5007-4aea-96be-283bece9e064"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["13774"]},"metadata":{},"execution_count":9}],"source":["count_stopwords(tokens)"]},{"cell_type":"markdown","metadata":{"id":"35A1dw9BvtFq"},"source":["_**Expected output:**_\n","\n","```python\n","count_stopwords(tokens) == 13774\n","```"]},{"cell_type":"markdown","metadata":{"id":"LNlJ28RmvtFr"},"source":["## Question 3\n","\n","How many **unique** words are in the text?\n","\n","_**Function Specifications:**_\n","* Function should take a `list` as input and return an `int` "]},{"cell_type":"code","execution_count":10,"metadata":{"id":"GuE4QTOqvtFr","executionInfo":{"status":"ok","timestamp":1675888772957,"user_tz":-120,"elapsed":6,"user":{"displayName":"Mahomed Saajid Cassim","userId":"03411706528132358067"}}},"outputs":[],"source":["### START FUNCTION\n","def unique_words(token_list):\n","    # your code here\n","    count = len(set(token_list))\n","    return count\n","    \n","### END FUNCTION"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_DP3iVqZvtFr"},"outputs":[],"source":["unique_words(tokens)"]},{"cell_type":"markdown","metadata":{"id":"Wb1TkwkQvtFr"},"source":["_**Expected output:**_\n","\n","```python\n","unique_words(tokens) == 2749\n","```"]},{"cell_type":"markdown","metadata":{"id":"BkZlS1xTvtFr"},"source":["## Question 4"]},{"cell_type":"markdown","metadata":{"id":"0GUQtipfvtFs"},"source":["What is the kth most frequently occuring word in the bag of words?\n","\n","_**Function Specifications:**_\n","* Function should take a `dict` and an `int` k as input\n","* Function should return the kth most common word as a `str`\n","\n","_Hint : bag_of_words already does not include stopwords_\n","\n","Example: \n","```python\n","most_common_word(bag = {'apple': 30, 'orange': 12, 'pear': 50, 'banana': 12}, 2)\n","\n",">>> 'apple'\n","```"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"R6KP2AbmvtFs","executionInfo":{"status":"ok","timestamp":1675888792806,"user_tz":-120,"elapsed":10,"user":{"displayName":"Mahomed Saajid Cassim","userId":"03411706528132358067"}}},"outputs":[],"source":["### START FUNCTION\n","def most_common_word(bag, k):\n","    # your code here\n","    sorted_bag = sorted(bag_of_words.items(), key=lambda x: x[1], reverse=True)\n","    result = str(sorted_bag[k-1][0])\n","    return result\n","\n","### END FUNCTION"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Q6LngYgvtFs"},"outputs":[],"source":["most_common_word(bag_of_words, 3)"]},{"cell_type":"markdown","metadata":{"id":"dmBvac0ovtFs"},"source":["_**Expected output:**_\n","\n","```python\n","most_common_word(bag_of_words, 3) == 'little'\n","\n","```"]},{"cell_type":"markdown","metadata":{"id":"KIMSIkcTvtFs"},"source":["## Question 5\n","\n","How many words appear n times in the text?\n","\n","_**Function Specifications:**_\n","* Input is taken as a `dict` and an `int` n, where n is the number of times the word appears in the text\n","* Count the number of words that appear n times in the text\n","* Output should be the count as an `int`\n","\n","Example: \n","```python\n","word_frequency_count(bag = {'apple': 30, 'orange': 12, 'pear': 50, 'banana': 12}, 12)\n","\n",">>> 2\n","```"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"kCaDhi4FvtFt","executionInfo":{"status":"ok","timestamp":1675888820386,"user_tz":-120,"elapsed":427,"user":{"displayName":"Mahomed Saajid Cassim","userId":"03411706528132358067"}}},"outputs":[],"source":["### START FUNCTION\n","\n","def word_frequency_count(bag, n):\n","    # your code here\n","    count = list(bag_of_words.values())\n","    finder = 0\n","    for x in count:\n","        if x == n:\n","            finder+=1\n","    return finder\n","### END FUNCTION"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zjVKn7rHvtFt","executionInfo":{"status":"ok","timestamp":1675888827179,"user_tz":-120,"elapsed":7,"user":{"displayName":"Mahomed Saajid Cassim","userId":"03411706528132358067"}},"outputId":"130d1390-b627-4fb2-c562-c23afcf3a578"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["97"]},"metadata":{},"execution_count":15}],"source":["word_frequency_count(bag_of_words, 5)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PXmc7cCyvtFt","executionInfo":{"status":"ok","timestamp":1675888829544,"user_tz":-120,"elapsed":390,"user":{"displayName":"Mahomed Saajid Cassim","userId":"03411706528132358067"}},"outputId":"6c098c01-9bf0-4877-b42e-a68f7433819e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["49"]},"metadata":{},"execution_count":16}],"source":["word_frequency_count(bag_of_words, 8)"]},{"cell_type":"markdown","metadata":{"id":"iSx-xRLCvtFt"},"source":["_**Expected output:**_\n","\n","```python\n","most_common_word(bag_of_words, 5) == 97\n","most_common_word(bag_of_words, 8) == 49\n","\n","```"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}